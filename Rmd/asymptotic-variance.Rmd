---
title: "Asymptotic Variance"
author: "Guillaume Blanc"
date: "1 septembre 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::load_all()
```

## Computing the Relative Asymptotic Variance of the Estimator

To compute the relative asymptotic variance of the estimator, we need:

* the asymptotic variance of the maximum likelihood estimator
* the asymptotic variance of our estimator
* take the ratio of the trace of the latter to the trace of the former

We'll do that for the factor loadings.

### Asymptotic Variance of the MLE

Given a log-likelihood function $L(\theta)$ and its score function $s(Y, \theta)$, the Avar of the MLE can be written as $Avar = I(\theta)^{-1}$ where

$$
I(\theta) = E_{\theta} \left[s(Y, \theta)s(Y, \theta)^\top\right]
$$
To compute this quantity, we'll use the empirical version:

$$
\bar I(\theta) = \frac{1}{n}\sum_{i=1}^n s(Y_i, \theta)s(Y_i, \theta)^\top, 
$$
where $Y_i$ are iid from $F_{\theta}$. We'll use $n$ large enough to reduce the variance of this estimator to reasonable levels for the current application.

We have the following:

\begin{align*}
  s\left(\theta\vert y_i\right) 
    &= \frac{\partial }{\partial \theta}\log \left(\int f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)        \phi(Z)dZ\right) \\
    &= \frac
    {\int \frac{\partial }{\partial \theta} f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)        \phi(Z)dZ}
    {\int f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)        \phi(Z)dZ}\\
    &= \frac
    {\int \frac{\partial }{\partial \theta} \left(\log f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)\right) f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)  \phi(Z)dZ}
    {\int f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)        \phi(Z)dZ}\\
    &\equiv \frac{N(\theta, y_i)}{D(\theta, y_i)}
\end{align*}


We need the following functions:

* `fYZ`: returns the conditional density $f_{Y|Z}$
* `dlogfYZ`: returns the derivative of the log of the conditional density with respect to the loadings
* `fZ`: returns the density of Z

Then we need to compute $\bar I(\theta)$, which involves many replications of the above, for each $Y$: given $Y$, we need to generate Z and compute the empirical version of $N$ and $D$ above, separately.

$$
\bar N(\theta, y_i) = \frac{1}{n_N}\sum_{i=1}^{n_N}  \frac{\partial }{\partial \theta} \left(\log f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)\right) f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)
$$

$$
\bar D(\theta, y_i) = \frac{1}{n_D}\sum_{i=1}^{n_D}  f_{Y_{i}|Z}(y_{i}|Z, x_i, \theta)
$$

Let's write the conditional density $f_{Y|Z}$ again:

$$
f_{Y_{i}|Z_i}(y_{i}\vert Z_i,x_i,\theta) = \prod_{j=1}^p \exp\left(\frac{y_{ij}\eta_{ij} - b_j(\eta_{ij})}{\tau_j} + c_j(y_{ij}, \tau_j)\right)
$$


### Function Definitions
To do so, we need the following cuntions

```{r cars}
# b and c functions
bfunc <- function(natpar){
  natpar - log(sigmoid(natpar))
}
cfunc <- function(Y, psi){
  Y * 0
}

# conditional distribution of Y (n * p matrix) given Z (n * q matrix), returns n-vector

fYZ <- function(Y, Z, par){
  natpar <- Z %*% t(par$A) 
  dens <- exp(t(t(Y * natpar - bfunc(natpar))/par$psi) + cfunc(Y, par$psi))
  apply(dens, 1, prod)
}

# Returns D() for each of the observations, so a n-vector
compute_D <- function(Y, par, nD){
  n <- nrow(Y)
  q <- ncol(par$A)
  rowMeans(sapply(1:nD, function(na){
    Z <- gen_Z(n = n, q=q)
    fYZ(Y, Z, par)
  }))
}
```

###  Code

```{r}
# generate the parameters 
n <- 1000
nD <- 100
p <- 5
q <- 1
par0 <- gen_par(p, q, k=0, family="bernoulli")
par1 <- par0
par1$A <- par1$A

gllvm_dat <- gen_gllvm(n, p, q, k=0, family="bernoulli", par=par0)
Y0 <- gllvm_dat$Y

```


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
